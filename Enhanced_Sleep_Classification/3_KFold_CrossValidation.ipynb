{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a666056",
   "metadata": {},
   "source": [
    "# K-Fold Cross-Validation Training\n",
    "This notebook implements robust stratified K-Fold cross-validation for sleep disorder classification.\n",
    "\n",
    "## Why K-Fold Cross-Validation?\n",
    "- ‚úÖ **More Reliable Metrics**: Uses entire dataset for both training and validation\n",
    "- ‚úÖ **Reduced Variance**: Averages performance across multiple folds\n",
    "- ‚úÖ **Better Generalization**: Ensures model performs well on different data splits\n",
    "- ‚úÖ **Industry Standard**: Professional approach for model evaluation\n",
    "- ‚úÖ **Class Balance**: Stratified splits maintain class distribution\n",
    "\n",
    "## Process:\n",
    "1. Split data into K folds (typically 5 or 10)\n",
    "2. Train model K times, each time using different fold as validation\n",
    "3. Average metrics across all folds\n",
    "4. Report mean and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1074113a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from time import time\n",
    "import json\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffa1ac4",
   "metadata": {},
   "source": [
    "## 1. K-Fold Cross-Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ea9ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_cross_validation(model_builder, X, y, n_splits=5, epochs=150, batch_size=64, \n",
    "                          random_state=42, verbose=1):\n",
    "    \"\"\"\n",
    "    Perform K-Fold cross-validation for model training\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model_builder : function\n",
    "        Function that returns a compiled model\n",
    "    X : array, shape (n_samples, n_timesteps, n_features)\n",
    "        Input data\n",
    "    y : array, shape (n_samples,)\n",
    "        Target labels\n",
    "    n_splits : int\n",
    "        Number of folds\n",
    "    epochs : int\n",
    "        Maximum epochs per fold\n",
    "    batch_size : int\n",
    "        Batch size for training\n",
    "    random_state : int\n",
    "        Random seed for reproducibility\n",
    "    verbose : int\n",
    "        Verbosity level (0, 1, or 2)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    results : dict\n",
    "        Dictionary containing all fold results and statistics\n",
    "    models : list\n",
    "        List of trained models from each fold\n",
    "    histories : list\n",
    "        List of training histories from each fold\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize stratified K-fold\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    # Storage for results\n",
    "    fold_results = []\n",
    "    models = []\n",
    "    histories = []\n",
    "    all_y_true = []\n",
    "    all_y_pred = []\n",
    "    all_y_pred_proba = []\n",
    "    \n",
    "    # Callbacks\n",
    "    early_stopping = keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=30,\n",
    "        restore_best_weights=True,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=10,\n",
    "        min_lr=1e-6,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Starting {n_splits}-Fold Cross-Validation\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Total samples: {len(X)}\")\n",
    "    print(f\"Samples per fold (approx): {len(X) // n_splits}\")\n",
    "    print(f\"Class distribution: {np.bincount(y.astype(int))}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Iterate through folds\n",
    "    fold_start_time = time()\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"üìÅ FOLD {fold}/{n_splits}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        # Split data\n",
    "        X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n",
    "        y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n",
    "        \n",
    "        print(f\"Training samples: {len(X_train_fold)}\")\n",
    "        print(f\"Validation samples: {len(X_val_fold)}\")\n",
    "        print(f\"Train class distribution: {np.bincount(y_train_fold.astype(int))}\")\n",
    "        print(f\"Val class distribution: {np.bincount(y_val_fold.astype(int))}\")\n",
    "        \n",
    "        # Build fresh model for this fold\n",
    "        model = model_builder()\n",
    "        \n",
    "        # Train model\n",
    "        print(f\"\\nüöÄ Training fold {fold}...\")\n",
    "        fold_train_start = time()\n",
    "        \n",
    "        history = model.fit(\n",
    "            X_train_fold, y_train_fold,\n",
    "            validation_data=(X_val_fold, y_val_fold),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=[early_stopping, reduce_lr],\n",
    "            verbose=verbose,\n",
    "            shuffle=True\n",
    "        )\n",
    "        \n",
    "        fold_train_time = time() - fold_train_start\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        y_pred_proba = model.predict(X_val_fold, verbose=0)\n",
    "        y_pred = (y_pred_proba > 0.5).astype(int).flatten()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        fold_metrics = {\n",
    "            'fold': fold,\n",
    "            'accuracy': accuracy_score(y_val_fold, y_pred),\n",
    "            'precision': precision_score(y_val_fold, y_pred, zero_division=0),\n",
    "            'recall': recall_score(y_val_fold, y_pred, zero_division=0),\n",
    "            'f1_score': f1_score(y_val_fold, y_pred, zero_division=0),\n",
    "            'roc_auc': roc_auc_score(y_val_fold, y_pred_proba),\n",
    "            'training_time': fold_train_time,\n",
    "            'epochs_trained': len(history.history['loss'])\n",
    "        }\n",
    "        \n",
    "        # Calculate specificity\n",
    "        cm = confusion_matrix(y_val_fold, y_pred)\n",
    "        if cm.shape == (2, 2):\n",
    "            tn, fp, fn, tp = cm.ravel()\n",
    "            fold_metrics['specificity'] = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "        else:\n",
    "            fold_metrics['specificity'] = 0\n",
    "        \n",
    "        fold_results.append(fold_metrics)\n",
    "        models.append(model)\n",
    "        histories.append(history)\n",
    "        all_y_true.extend(y_val_fold)\n",
    "        all_y_pred.extend(y_pred)\n",
    "        all_y_pred_proba.extend(y_pred_proba.flatten())\n",
    "        \n",
    "        # Print fold results\n",
    "        print(f\"\\nüìä Fold {fold} Results:\")\n",
    "        print(f\"  Accuracy:    {fold_metrics['accuracy']:.4f}\")\n",
    "        print(f\"  Precision:   {fold_metrics['precision']:.4f}\")\n",
    "        print(f\"  Recall:      {fold_metrics['recall']:.4f}\")\n",
    "        print(f\"  Specificity: {fold_metrics['specificity']:.4f}\")\n",
    "        print(f\"  F1-Score:    {fold_metrics['f1_score']:.4f}\")\n",
    "        print(f\"  ROC-AUC:     {fold_metrics['roc_auc']:.4f}\")\n",
    "        print(f\"  Training time: {fold_train_time:.2f}s ({fold_metrics['epochs_trained']} epochs)\")\n",
    "    \n",
    "    total_cv_time = time() - fold_start_time\n",
    "    \n",
    "    # Calculate aggregate statistics\n",
    "    df_results = pd.DataFrame(fold_results)\n",
    "    \n",
    "    summary_stats = {\n",
    "        'mean_accuracy': df_results['accuracy'].mean(),\n",
    "        'std_accuracy': df_results['accuracy'].std(),\n",
    "        'mean_precision': df_results['precision'].mean(),\n",
    "        'std_precision': df_results['precision'].std(),\n",
    "        'mean_recall': df_results['recall'].mean(),\n",
    "        'std_recall': df_results['recall'].std(),\n",
    "        'mean_specificity': df_results['specificity'].mean(),\n",
    "        'std_specificity': df_results['specificity'].std(),\n",
    "        'mean_f1': df_results['f1_score'].mean(),\n",
    "        'std_f1': df_results['f1_score'].std(),\n",
    "        'mean_roc_auc': df_results['roc_auc'].mean(),\n",
    "        'std_roc_auc': df_results['roc_auc'].std(),\n",
    "        'total_training_time': df_results['training_time'].sum(),\n",
    "        'mean_training_time': df_results['training_time'].mean(),\n",
    "        'total_cv_time': total_cv_time\n",
    "    }\n",
    "    \n",
    "    # Print final summary\n",
    "    print(f\"\\n\\n{'='*70}\")\n",
    "    print(f\"üìà CROSS-VALIDATION SUMMARY ({n_splits} folds)\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"\\nüéØ Performance Metrics (Mean ¬± Std):\")\n",
    "    print(f\"  Accuracy:    {summary_stats['mean_accuracy']:.4f} ¬± {summary_stats['std_accuracy']:.4f}\")\n",
    "    print(f\"  Precision:   {summary_stats['mean_precision']:.4f} ¬± {summary_stats['std_precision']:.4f}\")\n",
    "    print(f\"  Recall:      {summary_stats['mean_recall']:.4f} ¬± {summary_stats['std_recall']:.4f}\")\n",
    "    print(f\"  Specificity: {summary_stats['mean_specificity']:.4f} ¬± {summary_stats['std_specificity']:.4f}\")\n",
    "    print(f\"  F1-Score:    {summary_stats['mean_f1']:.4f} ¬± {summary_stats['std_f1']:.4f}\")\n",
    "    print(f\"  ROC-AUC:     {summary_stats['mean_roc_auc']:.4f} ¬± {summary_stats['std_roc_auc']:.4f}\")\n",
    "    print(f\"\\n‚è±Ô∏è  Training Time:\")\n",
    "    print(f\"  Per fold (avg): {summary_stats['mean_training_time']:.2f}s\")\n",
    "    print(f\"  Total CV time:  {total_cv_time:.2f}s ({total_cv_time/60:.2f} min)\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Compile results\n",
    "    results = {\n",
    "        'fold_results': fold_results,\n",
    "        'summary_stats': summary_stats,\n",
    "        'all_predictions': {\n",
    "            'y_true': np.array(all_y_true),\n",
    "            'y_pred': np.array(all_y_pred),\n",
    "            'y_pred_proba': np.array(all_y_pred_proba)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return results, models, histories\n",
    "\n",
    "print(\"‚úÖ K-Fold cross-validation function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81dbed9",
   "metadata": {},
   "source": [
    "## 2. Results Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b02a415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kfold_results(results, save_path=None):\n",
    "    \"\"\"\n",
    "    Visualize K-Fold cross-validation results\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    results : dict\n",
    "        Results dictionary from kfold_cross_validation\n",
    "    save_path : str or None\n",
    "        Path to save figure\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(results['fold_results'])\n",
    "    metrics = ['accuracy', 'precision', 'recall', 'specificity', 'f1_score', 'roc_auc']\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, metric in enumerate(metrics):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # Bar plot for each fold\n",
    "        bars = ax.bar(df['fold'], df[metric], alpha=0.7, color='steelblue', edgecolor='black')\n",
    "        \n",
    "        # Add mean line\n",
    "        mean_val = df[metric].mean()\n",
    "        ax.axhline(mean_val, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_val:.4f}')\n",
    "        \n",
    "        # Styling\n",
    "        ax.set_xlabel('Fold', fontsize=11, fontweight='bold')\n",
    "        ax.set_ylabel(metric.replace('_', ' ').title(), fontsize=11, fontweight='bold')\n",
    "        ax.set_title(f'{metric.replace(\"_\", \" \").title()} per Fold', fontsize=12, fontweight='bold')\n",
    "        ax.set_ylim([0, 1.05])\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{height:.3f}',\n",
    "                   ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    plt.suptitle('K-Fold Cross-Validation Results', fontsize=16, fontweight='bold', y=1.00)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"‚úÖ Figure saved to {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "print(\"‚úÖ Visualization functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e147f6",
   "metadata": {},
   "source": [
    "## 3. Comparison Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202348c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics_boxplot(results, save_path=None):\n",
    "    \"\"\"\n",
    "    Create boxplot showing distribution of metrics across folds\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(results['fold_results'])\n",
    "    metrics = ['accuracy', 'precision', 'recall', 'specificity', 'f1_score', 'roc_auc']\n",
    "    \n",
    "    # Prepare data for boxplot\n",
    "    data_to_plot = [df[metric].values for metric in metrics]\n",
    "    labels = [m.replace('_', ' ').title() for m in metrics]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 7))\n",
    "    \n",
    "    bp = ax.boxplot(data_to_plot, labels=labels, patch_artist=True,\n",
    "                    notch=True, showmeans=True,\n",
    "                    boxprops=dict(facecolor='lightblue', alpha=0.7),\n",
    "                    medianprops=dict(color='red', linewidth=2),\n",
    "                    meanprops=dict(marker='D', markerfacecolor='green', markersize=8))\n",
    "    \n",
    "    ax.set_ylabel('Score', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Distribution of Metrics Across K-Folds', fontsize=14, fontweight='bold')\n",
    "    ax.set_ylim([0, 1.05])\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add legend\n",
    "    ax.legend([bp['medians'][0], bp['means'][0]], \n",
    "             ['Median', 'Mean'], \n",
    "             loc='lower left', fontsize=10)\n",
    "    \n",
    "    plt.xticks(rotation=15, ha='right')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"‚úÖ Boxplot saved to {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "print(\"‚úÖ Boxplot function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe437d8",
   "metadata": {},
   "source": [
    "## 4. Training History Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627e96b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_histories(histories, save_path=None):\n",
    "    \"\"\"\n",
    "    Plot training histories from all folds\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "    \n",
    "    # Plot accuracy\n",
    "    for i, history in enumerate(histories, 1):\n",
    "        axes[0].plot(history.history['accuracy'], alpha=0.5, label=f'Fold {i} Train')\n",
    "        axes[0].plot(history.history['val_accuracy'], alpha=0.5, linestyle='--', label=f'Fold {i} Val')\n",
    "    \n",
    "    axes[0].set_xlabel('Epoch', fontsize=11, fontweight='bold')\n",
    "    axes[0].set_ylabel('Accuracy', fontsize=11, fontweight='bold')\n",
    "    axes[0].set_title('Training & Validation Accuracy Across Folds', fontsize=12, fontweight='bold')\n",
    "    axes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot loss\n",
    "    for i, history in enumerate(histories, 1):\n",
    "        axes[1].plot(history.history['loss'], alpha=0.5, label=f'Fold {i} Train')\n",
    "        axes[1].plot(history.history['val_loss'], alpha=0.5, linestyle='--', label=f'Fold {i} Val')\n",
    "    \n",
    "    axes[1].set_xlabel('Epoch', fontsize=11, fontweight='bold')\n",
    "    axes[1].set_ylabel('Loss', fontsize=11, fontweight='bold')\n",
    "    axes[1].set_title('Training & Validation Loss Across Folds', fontsize=12, fontweight='bold')\n",
    "    axes[1].legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"‚úÖ Training history plot saved to {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "print(\"‚úÖ Training history plotting function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fba82d",
   "metadata": {},
   "source": [
    "## 5. Save Results Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6ab179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_kfold_results(results, save_dir='./kfold_results'):\n",
    "    \"\"\"\n",
    "    Save K-Fold results to files\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    results : dict\n",
    "        Results from kfold_cross_validation\n",
    "    save_dir : str\n",
    "        Directory to save results\n",
    "    \"\"\"\n",
    "    import os\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Save fold results as CSV\n",
    "    df_folds = pd.DataFrame(results['fold_results'])\n",
    "    df_folds.to_csv(f\"{save_dir}/fold_results.csv\", index=False)\n",
    "    print(f\"‚úÖ Fold results saved to {save_dir}/fold_results.csv\")\n",
    "    \n",
    "    # Save summary statistics as JSON\n",
    "    with open(f\"{save_dir}/summary_stats.json\", 'w') as f:\n",
    "        json.dump(results['summary_stats'], f, indent=4)\n",
    "    print(f\"‚úÖ Summary statistics saved to {save_dir}/summary_stats.json\")\n",
    "    \n",
    "    # Save predictions\n",
    "    np.save(f\"{save_dir}/y_true.npy\", results['all_predictions']['y_true'])\n",
    "    np.save(f\"{save_dir}/y_pred.npy\", results['all_predictions']['y_pred'])\n",
    "    np.save(f\"{save_dir}/y_pred_proba.npy\", results['all_predictions']['y_pred_proba'])\n",
    "    print(f\"‚úÖ Predictions saved to {save_dir}/\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ All results saved to {save_dir}/\")\n",
    "\n",
    "print(\"‚úÖ Save results function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313f30ea",
   "metadata": {},
   "source": [
    "## 6. Example Usage Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166a5aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage (uncomment to use):\n",
    "# \n",
    "# # Define model builder function\n",
    "# def create_model():\n",
    "#     from tensorflow import keras\n",
    "#     model = keras.Sequential([\n",
    "#         keras.layers.Input(shape=(1024, 1)),\n",
    "#         keras.layers.Conv1D(32, 7, activation='relu', padding='same'),\n",
    "#         keras.layers.MaxPooling1D(2),\n",
    "#         keras.layers.LSTM(64),\n",
    "#         keras.layers.Dense(32, activation='relu'),\n",
    "#         keras.layers.Dense(1, activation='sigmoid')\n",
    "#     ])\n",
    "#     model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#     return model\n",
    "# \n",
    "# # Load your data\n",
    "# # X = ...\n",
    "# # y = ...\n",
    "# \n",
    "# # Run K-Fold CV\n",
    "# results, models, histories = kfold_cross_validation(\n",
    "#     model_builder=create_model,\n",
    "#     X=X,\n",
    "#     y=y,\n",
    "#     n_splits=5,\n",
    "#     epochs=100,\n",
    "#     batch_size=64,\n",
    "#     verbose=1\n",
    "# )\n",
    "# \n",
    "# # Visualize results\n",
    "# plot_kfold_results(results, save_path='kfold_metrics.png')\n",
    "# plot_metrics_boxplot(results, save_path='kfold_boxplot.png')\n",
    "# plot_training_histories(histories, save_path='kfold_training.png')\n",
    "# \n",
    "# # Save results\n",
    "# save_kfold_results(results, save_dir='./my_kfold_results')\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ K-Fold Cross-Validation utilities loaded successfully!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nAvailable functions:\")\n",
    "print(\"  - kfold_cross_validation(model_builder, X, y, n_splits, ...)\")\n",
    "print(\"  - plot_kfold_results(results, save_path)\")\n",
    "print(\"  - plot_metrics_boxplot(results, save_path)\")\n",
    "print(\"  - plot_training_histories(histories, save_path)\")\n",
    "print(\"  - save_kfold_results(results, save_dir)\")\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
