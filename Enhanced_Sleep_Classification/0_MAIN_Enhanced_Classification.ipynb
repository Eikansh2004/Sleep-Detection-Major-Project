{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a61fe66",
   "metadata": {},
   "source": [
    "# üéØ Enhanced Sleep Disorder Classification - Complete Pipeline\n",
    "\n",
    "## üìå Project Overview\n",
    "This notebook implements state-of-the-art deep learning techniques for binary sleep disorder classification (Healthy vs Unhealthy).\n",
    "\n",
    "## üöÄ Key Improvements Over Baseline:\n",
    "1. **Attention-Enhanced BiLSTM-CNN Architecture**\n",
    "   - Bidirectional LSTM for temporal context\n",
    "   - Attention mechanism for feature importance\n",
    "   - Skip connections for better gradient flow\n",
    "\n",
    "2. **Advanced Data Augmentation**\n",
    "   - Time warping, magnitude warping\n",
    "   - Jittering, scaling, time shifting\n",
    "   - Window slicing and rotation\n",
    "\n",
    "3. **Stratified K-Fold Cross-Validation**\n",
    "   - More reliable performance estimates\n",
    "   - Reduced variance in metrics\n",
    "   - Better generalization assessment\n",
    "\n",
    "4. **Model Ensemble**\n",
    "   - Combines multiple models for robustness\n",
    "   - Weighted voting based on performance\n",
    "   - Improved accuracy and reliability\n",
    "\n",
    "5. **Comprehensive Visualization**\n",
    "   - Training history analysis\n",
    "   - Confusion matrices\n",
    "   - ROC/PR curves\n",
    "   - Attention weight visualization\n",
    "\n",
    "## üìä Expected Performance Improvements:\n",
    "- **Accuracy**: +3-7% over baseline\n",
    "- **ROC-AUC**: +2-5% improvement\n",
    "- **F1-Score**: +3-6% boost\n",
    "- **Robustness**: Significantly better generalization\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737fef09",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af19c4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Deep learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.layers as tfl\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b92e9bc",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Load Dataset\n",
    "\n",
    "**Note**: Update the file path to match your data location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1b5b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Update this path to your dataset location\n",
    "DATA_PATH = 'path/to/your/healthy_unhealthy1.csv'\n",
    "\n",
    "# Load data\n",
    "try:\n",
    "    data = np.loadtxt(DATA_PATH, delimiter=',')\n",
    "    print(f\"‚úÖ Data loaded successfully!\")\n",
    "    print(f\"   Shape: {data.shape}\")\n",
    "    \n",
    "    # Split features and labels\n",
    "    X = data[:, 0:1024]  # First 1024 columns are features\n",
    "    y = data[:, -1]      # Last column is label (0=Healthy, 1=Unhealthy)\n",
    "    \n",
    "    print(f\"\\nüìä Dataset Statistics:\")\n",
    "    print(f\"   Total samples: {len(X)}\")\n",
    "    print(f\"   Feature dimensions: {X.shape[1]}\")\n",
    "    print(f\"   Healthy samples: {np.sum(y == 0)} ({np.sum(y == 0)/len(y)*100:.1f}%)\")\n",
    "    print(f\"   Unhealthy samples: {np.sum(y == 1)} ({np.sum(y == 1)/len(y)*100:.1f}%)\")\n",
    "    print(f\"   Class balance ratio: {np.sum(y == 0) / np.sum(y == 1):.2f}:1\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Data file not found!\")\n",
    "    print(\"Please update DATA_PATH with your dataset location.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ab51f4",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Data Preparation & Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfa9f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the data augmentation notebook to load functions\n",
    "%run \"1_Data_Augmentation_Utils.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3b5da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    shuffle=True, \n",
    "    stratify=y,  # Maintain class balance\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"üìä Data Split:\")\n",
    "print(f\"   Training set: {len(X_train)} samples\")\n",
    "print(f\"   Test set: {len(X_test)} samples\")\n",
    "print(f\"   Train class distribution: {np.bincount(y_train.astype(int))}\")\n",
    "print(f\"   Test class distribution: {np.bincount(y_test.astype(int))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc5d698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply data augmentation (OPTIONAL - comment out if you want to skip augmentation)\n",
    "APPLY_AUGMENTATION = True  # Set to False to skip augmentation\n",
    "AUGMENTATION_FACTOR = 1     # How many augmented copies per sample (0 = no augmentation)\n",
    "\n",
    "if APPLY_AUGMENTATION and AUGMENTATION_FACTOR > 0:\n",
    "    print(\"üîÑ Applying data augmentation...\")\n",
    "    X_train_aug, y_train_aug = augment_dataset(\n",
    "        X_train, y_train,\n",
    "        augmentation_factor=AUGMENTATION_FACTOR,\n",
    "        augmentation_methods=['jitter', 'scaling', 'time_warp', 'magnitude_warp']\n",
    "    )\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è Skipping data augmentation\")\n",
    "    X_train_aug, y_train_aug = X_train, y_train\n",
    "\n",
    "# Reshape for CNN input (samples, timesteps, features)\n",
    "X_train_aug = X_train_aug.reshape(-1, 1024, 1)\n",
    "X_test_reshaped = X_test.reshape(-1, 1024, 1)\n",
    "\n",
    "print(f\"\\n‚úÖ Final training data shape: {X_train_aug.shape}\")\n",
    "print(f\"‚úÖ Final test data shape: {X_test_reshaped.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02de3d2",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Build Attention-Enhanced Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bcbf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model architecture\n",
    "%run \"2_Attention_BiLSTM_CNN_Model.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fef257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and compile model\n",
    "input_shape = (1024, 1)\n",
    "\n",
    "print(\"üèóÔ∏è Building Attention-Enhanced BiLSTM-CNN model...\")\n",
    "model = build_attention_bilstm_cnn(input_shape, use_attention=True)\n",
    "model = compile_attention_model(model, learning_rate=0.001)\n",
    "\n",
    "# Display model summary\n",
    "model.summary()\n",
    "\n",
    "print(f\"\\n‚úÖ Model built successfully!\")\n",
    "print(f\"   Total parameters: {model.count_params():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3751d809",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Train Model with Advanced Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec561c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "EPOCHS = 150\n",
    "BATCH_SIZE = 64\n",
    "MODEL_SAVE_PATH = 'best_attention_model.h5'\n",
    "\n",
    "print(\"üöÄ Starting model training...\\n\")\n",
    "\n",
    "history, training_time = train_attention_model(\n",
    "    model=model,\n",
    "    x_train=X_train_aug,\n",
    "    y_train=y_train_aug,\n",
    "    x_val=None,  # Will use validation_split=0.2\n",
    "    y_val=None,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    save_path=MODEL_SAVE_PATH\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Training completed!\")\n",
    "print(f\"   Total time: {training_time:.2f} seconds ({training_time/60:.2f} minutes)\")\n",
    "print(f\"   Model saved to: {MODEL_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8cc3eb",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd796fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load visualization utilities\n",
    "%run \"5_Visualization_Results.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a413f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run complete visualization pipeline\n",
    "metrics = complete_visualization_pipeline(\n",
    "    model=model,\n",
    "    history=history,\n",
    "    X_test=X_test_reshaped,\n",
    "    y_test=y_test,\n",
    "    class_names=['Healthy', 'Unhealthy'],\n",
    "    save_dir='./results_attention_model'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981c1196",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ K-Fold Cross-Validation (OPTIONAL but RECOMMENDED)\n",
    "\n",
    "For more robust evaluation, run K-Fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021ecaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load K-Fold utilities\n",
    "%run \"3_KFold_CrossValidation.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9858ab68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Run K-Fold Cross-Validation\n",
    "RUN_KFOLD = False  # Set to True to run K-Fold CV (takes longer)\n",
    "\n",
    "if RUN_KFOLD:\n",
    "    print(\"üîÑ Starting K-Fold Cross-Validation...\\n\")\n",
    "    \n",
    "    # Define model builder function for K-Fold\n",
    "    def create_attention_model():\n",
    "        model = build_attention_bilstm_cnn((1024, 1), use_attention=True)\n",
    "        model = compile_attention_model(model, learning_rate=0.001)\n",
    "        return model\n",
    "    \n",
    "    # Run K-Fold CV\n",
    "    kfold_results, kfold_models, kfold_histories = kfold_cross_validation(\n",
    "        model_builder=create_attention_model,\n",
    "        X=X_train_aug,\n",
    "        y=y_train_aug,\n",
    "        n_splits=5,\n",
    "        epochs=100,\n",
    "        batch_size=64,\n",
    "        random_state=42,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Visualize K-Fold results\n",
    "    plot_kfold_results(kfold_results, save_path='./results_kfold/kfold_metrics.png')\n",
    "    plot_metrics_boxplot(kfold_results, save_path='./results_kfold/kfold_boxplot.png')\n",
    "    plot_training_histories(kfold_histories, save_path='./results_kfold/kfold_training.png')\n",
    "    \n",
    "    # Save K-Fold results\n",
    "    save_kfold_results(kfold_results, save_dir='./results_kfold')\n",
    "    \n",
    "else:\n",
    "    print(\"‚è≠Ô∏è Skipping K-Fold Cross-Validation (set RUN_KFOLD=True to enable)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737e8676",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Ensemble Methods (OPTIONAL)\n",
    "\n",
    "Combine multiple models for improved performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b22060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ensemble utilities\n",
    "%run \"4_Model_Ensemble.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7eb483d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Use ensemble if you have K-Fold models\n",
    "USE_ENSEMBLE = False  # Set to True if you ran K-Fold CV\n",
    "\n",
    "if USE_ENSEMBLE and RUN_KFOLD:\n",
    "    print(\"üéØ Creating model ensemble...\\n\")\n",
    "    \n",
    "    # Calculate optimal weights based on validation performance\n",
    "    # Note: You'd need a separate validation set for this\n",
    "    # For now, we'll use equal weights\n",
    "    \n",
    "    # Evaluate ensemble methods\n",
    "    ensemble_results = evaluate_ensemble_methods(\n",
    "        models=kfold_models,\n",
    "        X_test=X_test_reshaped,\n",
    "        y_test=y_test,\n",
    "        weights=None  # Equal weights\n",
    "    )\n",
    "    \n",
    "    # Visualize ensemble comparison\n",
    "    plot_ensemble_comparison(ensemble_results, save_path='./results_ensemble/ensemble_comparison.png')\n",
    "    plot_roc_curves_comparison(ensemble_results, y_test, save_path='./results_ensemble/ensemble_roc.png')\n",
    "    \n",
    "else:\n",
    "    print(\"‚è≠Ô∏è Skipping ensemble (set USE_ENSEMBLE=True and run K-Fold first)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee0792d",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Compare with Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21356a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a simple baseline for comparison\n",
    "print(\"üîÑ Training baseline CNN-LSTM model for comparison...\\n\")\n",
    "\n",
    "baseline_model = build_simple_cnn_lstm((1024, 1))\n",
    "baseline_model.compile(optimizer='adam', loss='binary_crossentropy', \n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "baseline_history = baseline_model.fit(\n",
    "    X_train_aug, y_train_aug,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Baseline model trained!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033b44c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate baseline\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "# Attention model predictions\n",
    "y_pred_attention_proba = model.predict(X_test_reshaped, verbose=0).flatten()\n",
    "y_pred_attention = (y_pred_attention_proba > 0.5).astype(int)\n",
    "\n",
    "# Baseline predictions\n",
    "y_pred_baseline_proba = baseline_model.predict(X_test_reshaped, verbose=0).flatten()\n",
    "y_pred_baseline = (y_pred_baseline_proba > 0.5).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "attention_metrics = {\n",
    "    'Accuracy': accuracy_score(y_test, y_pred_attention),\n",
    "    'F1-Score': f1_score(y_test, y_pred_attention),\n",
    "    'ROC-AUC': roc_auc_score(y_test, y_pred_attention_proba)\n",
    "}\n",
    "\n",
    "baseline_metrics = {\n",
    "    'Accuracy': accuracy_score(y_test, y_pred_baseline),\n",
    "    'F1-Score': f1_score(y_test, y_pred_baseline),\n",
    "    'ROC-AUC': roc_auc_score(y_test, y_pred_baseline_proba)\n",
    "}\n",
    "\n",
    "# Create comparison table\n",
    "comparison = {\n",
    "    'Attention-BiLSTM-CNN': attention_metrics,\n",
    "    'Baseline-CNN-LSTM': baseline_metrics\n",
    "}\n",
    "\n",
    "comparison_df = create_comparison_table(comparison, save_path='./model_comparison.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06211a5",
   "metadata": {},
   "source": [
    "## üîü Final Summary & Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596ca42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéä PROJECT SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüìä Dataset:\")\n",
    "print(f\"   Total samples: {len(X)}\")\n",
    "print(f\"   Training samples: {len(X_train_aug)}\")\n",
    "print(f\"   Test samples: {len(X_test)}\")\n",
    "\n",
    "print(\"\\nüèÜ Best Model Performance:\")\n",
    "print(f\"   Accuracy: {attention_metrics['Accuracy']*100:.2f}%\")\n",
    "print(f\"   F1-Score: {attention_metrics['F1-Score']*100:.2f}%\")\n",
    "print(f\"   ROC-AUC: {attention_metrics['ROC-AUC']*100:.2f}%\")\n",
    "\n",
    "print(\"\\nüìà Improvement Over Baseline:\")\n",
    "acc_improvement = (attention_metrics['Accuracy'] - baseline_metrics['Accuracy']) * 100\n",
    "f1_improvement = (attention_metrics['F1-Score'] - baseline_metrics['F1-Score']) * 100\n",
    "auc_improvement = (attention_metrics['ROC-AUC'] - baseline_metrics['ROC-AUC']) * 100\n",
    "\n",
    "print(f\"   Accuracy: {acc_improvement:+.2f}%\")\n",
    "print(f\"   F1-Score: {f1_improvement:+.2f}%\")\n",
    "print(f\"   ROC-AUC: {auc_improvement:+.2f}%\")\n",
    "\n",
    "print(\"\\nüíæ Saved Artifacts:\")\n",
    "print(f\"   - Best model: {MODEL_SAVE_PATH}\")\n",
    "print(f\"   - Visualizations: ./results_attention_model/\")\n",
    "print(f\"   - Comparison table: ./model_comparison.csv\")\n",
    "if RUN_KFOLD:\n",
    "    print(f\"   - K-Fold results: ./results_kfold/\")\n",
    "if USE_ENSEMBLE:\n",
    "    print(f\"   - Ensemble results: ./results_ensemble/\")\n",
    "\n",
    "print(\"\\nüéØ Key Techniques Used:\")\n",
    "print(\"   ‚úÖ Attention mechanism for feature focus\")\n",
    "print(\"   ‚úÖ Bidirectional LSTM for temporal context\")\n",
    "print(\"   ‚úÖ Skip connections for gradient flow\")\n",
    "print(\"   ‚úÖ Batch normalization for stability\")\n",
    "print(\"   ‚úÖ Data augmentation for generalization\")\n",
    "if RUN_KFOLD:\n",
    "    print(\"   ‚úÖ K-Fold cross-validation for robustness\")\n",
    "if USE_ENSEMBLE:\n",
    "    print(\"   ‚úÖ Model ensemble for improved accuracy\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ PROJECT COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f8a50e",
   "metadata": {},
   "source": [
    "## üìù Next Steps & Recommendations\n",
    "\n",
    "### For Project Submission:\n",
    "1. **Include all visualizations** from `results_attention_model/` directory\n",
    "2. **Present the comparison table** showing improvements over baseline\n",
    "3. **Highlight K-Fold CV results** if you ran them (shows rigorous evaluation)\n",
    "4. **Explain the architecture** with attention mechanism and BiLSTM\n",
    "5. **Discuss data augmentation** and its impact on generalization\n",
    "\n",
    "### Further Improvements:\n",
    "1. **Hyperparameter Tuning**: Use KerasTuner or Optuna for automated optimization\n",
    "2. **Transfer Learning**: Pre-train on larger sleep datasets if available\n",
    "3. **Multi-Class Classification**: Extend to classify specific sleep disorders\n",
    "4. **Real-Time Prediction**: Deploy model as web service or mobile app\n",
    "5. **Explainability**: Add SHAP or LIME for model interpretability\n",
    "\n",
    "### Presentation Tips:\n",
    "- Show before/after comparison with baseline\n",
    "- Demonstrate attention weights on sample signals\n",
    "- Present confusion matrix and ROC curves\n",
    "- Explain why each technique was chosen\n",
    "- Discuss limitations and future work\n",
    "\n",
    "---\n",
    "\n",
    "**Good luck with your project submission! üöÄ**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
